{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e2f274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: crewai==0.28.8 in c:\\users\\martha\\anaconda3\\lib\\site-packages (0.28.8)\n",
      "Requirement already satisfied: crewai_tools==0.1.6 in c:\\users\\martha\\anaconda3\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain_community==0.0.29 in c:\\users\\martha\\anaconda3\\lib\\site-packages (0.0.29)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (1.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (8.1.7)\n",
      "Requirement already satisfied: embedchain<0.2.0,>=0.1.98 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (0.1.113)\n",
      "Requirement already satisfied: instructor<0.6.0,>=0.5.2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (0.5.2)\n",
      "Requirement already satisfied: langchain<0.2.0,>=0.1.10 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (0.1.13)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.13.3 in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from crewai==0.28.8) (1.35.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (1.30.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from crewai==0.28.8) (2.7.4)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (1.0.0)\n",
      "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai==0.28.8) (2023.12.25)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai_tools==0.1.6) (4.13.3)\n",
      "Requirement already satisfied: chromadb<0.5.0,>=0.4.22 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai_tools==0.1.6) (0.4.24)\n",
      "Requirement already satisfied: lancedb<0.6.0,>=0.5.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai_tools==0.1.6) (0.5.7)\n",
      "Requirement already satisfied: pyright<2.0.0,>=1.1.350 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai_tools==0.1.6) (1.1.394)\n",
      "Requirement already satisfied: pytest<9.0.0,>=8.0.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai_tools==0.1.6) (8.3.4)\n",
      "Requirement already satisfied: pytube<16.0.0,>=15.0.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai_tools==0.1.6) (15.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai_tools==0.1.6) (2.31.0)\n",
      "Requirement already satisfied: selenium<5.0.0,>=4.18.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from crewai_tools==0.1.6) (4.28.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain_community==0.0.29) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain_community==0.0.29) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain_community==0.0.29) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain_community==0.0.29) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain_community==0.0.29) (0.1.53)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain_community==0.0.29) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain_community==0.0.29) (1.26.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain_community==0.0.29) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (2.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (4.9.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.115.8)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.13.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.6.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.51b0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.9.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (32.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.10.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from click<9.0.0,>=8.1.7->crewai==0.28.8) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (0.9.0)\n",
      "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.14.1)\n",
      "Requirement already satisfied: clarifai<11.0.0,>=10.0.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (10.11.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.80.0)\n",
      "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.44)\n",
      "Requirement already satisfied: langchain-cohere<0.2.0,>=0.1.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.5)\n",
      "Requirement already satisfied: langchain-openai<0.2.0,>=0.1.7 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.7)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.3.1)\n",
      "Requirement already satisfied: pysbd<0.4.0,>=0.3.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.3.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (13.9.4)\n",
      "Requirement already satisfied: schema<0.8.0,>=0.7.5 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.7.5)\n",
      "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.7.0)\n",
      "Requirement already satisfied: PyGithub<2.0.0,>=1.59.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.59.1)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.38 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (3.1.44)\n",
      "Requirement already satisfied: youtube-transcript-api<0.7.0,>=0.6.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (0.6.3)\n",
      "Requirement already satisfied: yt_dlp<2024.0.0,>=2023.11.14 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2023.12.30)\n",
      "Requirement already satisfied: docstring-parser<0.16,>=0.15 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from instructor<0.6.0,>=0.5.2->crewai==0.28.8) (0.15)\n",
      "Requirement already satisfied: deprecation in c:\\users\\martha\\anaconda3\\lib\\site-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (2.1.0)\n",
      "Requirement already satisfied: pylance==0.9.18 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (0.9.18)\n",
      "Requirement already satisfied: ratelimiter~=1.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (1.2.0.post0)\n",
      "Requirement already satisfied: retry>=0.9.2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (0.9.2)\n",
      "Requirement already satisfied: semver>=3.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (3.0.4)\n",
      "Requirement already satisfied: cachetools in c:\\users\\martha\\anaconda3\\lib\\site-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (4.2.2)\n",
      "Requirement already satisfied: pyarrow>=12 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (14.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (0.0.2)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.27.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.8.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\martha\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.3.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.67.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.30.0)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-proto==1.30.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (5.29.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai==0.28.8) (0.51b0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (2.18.4)\n",
      "Requirement already satisfied: nodeenv>=1.6.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from pyright<2.0.0,>=1.1.350->crewai_tools==0.1.6) (1.9.1)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\martha\\anaconda3\\lib\\site-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2025.1.31)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (0.11.1)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.29) (3.0.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\martha\\anaconda3\\lib\\site-packages (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.3.9)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\martha\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.2.0)\n",
      "Requirement already satisfied: clarifai-grpc>=10.11.2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (11.1.1)\n",
      "Requirement already satisfied: clarifai-protocol>=0.0.14 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.0.14)\n",
      "Requirement already satisfied: tritonclient>=2.34.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.54.0)\n",
      "Requirement already satisfied: Pillow>=9.5.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (10.2.0)\n",
      "Requirement already satisfied: inquirerpy==0.3.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.3.4)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.9.0)\n",
      "Requirement already satisfied: fsspec==2024.6.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2024.6.1)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from schema<0.8.0,>=0.7.5->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (21.6.0)\n",
      "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.3.4)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.48)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.14.1)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.45.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (4.0.7)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.24.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.26.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.29.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.14.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.0.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai==0.28.8) (2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.8.2)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\martha\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.9)\n",
      "Requirement already satisfied: cohere<6.0,>=5.5 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (5.13.12)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\martha\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\martha\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (24.3.25)\n",
      "Requirement already satisfied: sympy in c:\\users\\martha\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.12)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.51b0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.2.1)\n",
      "Requirement already satisfied: pyjwt>=2.4.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2.4.0)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.5.0)\n",
      "Requirement already satisfied: decorator>=3.4.2 in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (5.1.1)\n",
      "Requirement already satisfied: py<2.0.0,>=1.4.26 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (1.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.28.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\martha\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\martha\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.3.0.post0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (1.0.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.7.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (14.2)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from youtube-transcript-api<0.7.0,>=0.6.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (0.7.1)\n",
      "Requirement already satisfied: mutagen in c:\\users\\martha\\anaconda3\\lib\\site-packages (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.47.0)\n",
      "Requirement already satisfied: pycryptodomex in c:\\users\\martha\\anaconda3\\lib\\site-packages (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (3.21.0)\n",
      "Requirement already satisfied: brotli in c:\\users\\martha\\anaconda3\\lib\\site-packages (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.0.9)\n",
      "Requirement already satisfied: pycparser in c:\\users\\martha\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (2.21)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.10.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.4.0)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.32.0.20241016)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (4.0.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.70.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.7.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.14.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\martha\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.13.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.0)\n",
      "Requirement already satisfied: cryptography>=3.3.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (42.0.2)\n",
      "Requirement already satisfied: python-rapidjson>=0.9.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from tritonclient>=2.34.0->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.20)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.5.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\martha\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit<4.0.0,>=3.0.1->inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.2.13)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\martha\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.4.8)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Installing collected packages: packaging\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "Successfully installed packaging-23.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "notebook 6.5.7 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\n",
      "spyder 5.4.3 requires jedi<0.19.0,>=0.17.2, but you have jedi 0.19.2 which is incompatible.\n",
      "streamlit 1.30.0 requires protobuf<5,>=3.20, but you have protobuf 5.29.3 which is incompatible.\n",
      "tensorflow-intel 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd3b3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7169634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb5a1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from utils import get_openai_api_key\n",
    "\n",
    "#openai_api_key = get_openai_api_key()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] =add api key here\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a549d5",
   "metadata": {},
   "source": [
    "To create an agent, create an instance of an agent class. you want to define the role, the goal and the backstory.\n",
    "Our agents will be planner, writer and editor agents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "920ac3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = Agent(\n",
    "    role=\"Content Planner\",\n",
    "    goal=\"Plan engaging and factually accurate content on {topic}\",\n",
    "    backstory=\"You're working on planning a blog article \"\n",
    "              \"about the topic: {topic}.\"\n",
    "              \"You collect information that helps the \"\n",
    "              \"audience learn something \"\n",
    "              \"and make informed decisions. \"\n",
    "              \"Your work is the basis for \"\n",
    "              \"the Content Writer to write an article on this topic.\",\n",
    "    allow_delegation=False,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5454dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = Agent(\n",
    "    role=\"Content Writer\",\n",
    "    goal=\"Write insightful and factually accurate \"\n",
    "         \"opinion piece about the topic: {topic}\",\n",
    "    backstory=\"You're working on a writing \"\n",
    "              \"a new opinion piece about the topic: {topic}. \"\n",
    "              \"You base your writing on the work of \"\n",
    "              \"the Content Planner, who provides an outline \"\n",
    "              \"and relevant context about the topic. \"\n",
    "              \"You follow the main objectives and \"\n",
    "              \"direction of the outline, \"\n",
    "              \"as provide by the Content Planner. \"\n",
    "              \"You also provide objective and impartial insights \"\n",
    "              \"and back them up with information \"\n",
    "              \"provide by the Content Planner. \"\n",
    "              \"You acknowledge in your opinion piece \"\n",
    "              \"when your statements are opinions \"\n",
    "              \"as opposed to objective statements.\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8512e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = Agent(\n",
    "    role=\"Editor\",\n",
    "    goal=\"Edit a given blog post to align with \"\n",
    "         \"the writing style of the organization. \",\n",
    "    backstory=\"You are an editor who receives a blog post \"\n",
    "              \"from the Content Writer. \"\n",
    "              \"Your goal is to review the blog post \"\n",
    "              \"to ensure that it follows journalistic best practices,\"\n",
    "              \"provides balanced viewpoints \"\n",
    "              \"when providing opinions or assertions, \"\n",
    "              \"and also avoids major controversial topics \"\n",
    "              \"or opinions when possible.\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be68686c",
   "metadata": {},
   "source": [
    "Then define instance of task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bc75e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = Task(\n",
    "    description=(\n",
    "        \"1. Prioritize the latest trends, key players, \"\n",
    "            \"and noteworthy news on {topic}.\\n\"\n",
    "        \"2. Identify the target audience, considering \"\n",
    "            \"their interests and pain points.\\n\"\n",
    "        \"3. Develop a detailed content outline including \"\n",
    "            \"an introduction, key points, and a call to action.\\n\"\n",
    "        \"4. Include SEO keywords and relevant data or sources.\"\n",
    "    ),\n",
    "    expected_output=\"A comprehensive content plan document \"\n",
    "        \"with an outline, audience analysis, \"\n",
    "        \"SEO keywords, and resources.\",\n",
    "    agent=planner,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af2acb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "write = Task(\n",
    "    description=(\n",
    "        \"1. Use the content plan to craft a compelling \"\n",
    "            \"blog post on {topic}.\\n\"\n",
    "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
    "\t\t\"3. Sections/Subtitles are properly named \"\n",
    "            \"in an engaging manner.\\n\"\n",
    "        \"4. Ensure the post is structured with an \"\n",
    "            \"engaging introduction, insightful body, \"\n",
    "            \"and a summarizing conclusion.\\n\"\n",
    "        \"5. Proofread for grammatical errors and \"\n",
    "            \"alignment with the brand's voice.\\n\"\n",
    "    ),\n",
    "    expected_output=\"A well-written blog post \"\n",
    "        \"in markdown format, ready for publication, \"\n",
    "        \"each section should have 2 or 3 paragraphs.\",\n",
    "    agent=writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "344a6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit = Task(\n",
    "    description=(\"Proofread the given blog post for \"\n",
    "                 \"grammatical errors and \"\n",
    "                 \"alignment with the brand's voice.\"),\n",
    "    expected_output=\"A well-written blog post in markdown format, \"\n",
    "                    \"ready for publication, \"\n",
    "                    \"each section should have 2 or 3 paragraphs.\",\n",
    "    agent=editor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dae596",
   "metadata": {},
   "source": [
    "Now we create and then run the crew. In this ex tasks are executed sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d672100",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[planner, writer, editor],\n",
    "    tasks=[plan, write, edit],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5ed7b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Content Planner\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. Prioritize the latest trends, key players, and noteworthy news on Large Language Models.\n",
      "2. Identify the target audience, considering their interests and pain points.\n",
      "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n",
      "4. Include SEO keywords and relevant data or sources.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
      "\n",
      "Final Answer: \n",
      "\n",
      "Title: Unleashing the Power of Large Language Models: A Comprehensive Guide\n",
      "\n",
      "Introduction:\n",
      "- Brief overview of Large Language Models (LLMs) and their significance in the field of artificial intelligence\n",
      "- Mention of key players in the industry such as OpenAI, Google, and Facebook\n",
      "- Recent advancements in LLM technology and their impact on various sectors\n",
      "\n",
      "Key Points:\n",
      "1. Understanding Large Language Models\n",
      "- Definition of LLMs and their capabilities in natural language processing\n",
      "- Examples of popular LLMs like GPT-3 and BERT\n",
      "- Potential applications of LLMs in chatbots, content generation, and more\n",
      "\n",
      "2. Latest Trends in Large Language Models\n",
      "- Discussion on the growing trend of using LLMs in various industries\n",
      "- Exploration of new research and developments in LLM technology\n",
      "- Impact of LLMs on the future of communication and information processing\n",
      "\n",
      "3. Key Players in the Industry\n",
      "- Overview of companies leading the development of LLMs\n",
      "- Comparison of different LLM models and their strengths\n",
      "- Collaboration between tech giants and research institutions in advancing LLM technology\n",
      "\n",
      "4. Target Audience Analysis\n",
      "- Identification of tech enthusiasts, data scientists, and AI researchers as primary audience\n",
      "- Understanding of audience interests in cutting-edge technology and AI applications\n",
      "- Addressing pain points related to understanding complex AI concepts and staying updated on industry trends\n",
      "\n",
      "Call to Action:\n",
      "- Encourage readers to explore the potential of LLMs in their respective fields\n",
      "- Provide resources for further reading on LLM technology and applications\n",
      "- Invite audience to share their thoughts and experiences with LLMs in the comments section\n",
      "\n",
      "SEO Keywords:\n",
      "- Large Language Models\n",
      "- GPT-3\n",
      "- BERT\n",
      "- Natural Language Processing\n",
      "- Artificial Intelligence\n",
      "- Tech Trends\n",
      "- AI Applications\n",
      "\n",
      "Resources:\n",
      "1. OpenAI's official website for updates on LLM research and projects\n",
      "2. Google AI Blog for insights on the latest advancements in AI technology\n",
      "3. Research papers on LLMs from academic institutions like Stanford and MIT\n",
      "\n",
      "Overall, this comprehensive content plan aims to educate and engage the audience on the topic of Large Language Models, providing valuable insights and resources for further exploration.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [DEBUG]: == [Content Planner] Task output: Title: Unleashing the Power of Large Language Models: A Comprehensive Guide\n",
      "\n",
      "Introduction:\n",
      "- Brief overview of Large Language Models (LLMs) and their significance in the field of artificial intelligence\n",
      "- Mention of key players in the industry such as OpenAI, Google, and Facebook\n",
      "- Recent advancements in LLM technology and their impact on various sectors\n",
      "\n",
      "Key Points:\n",
      "1. Understanding Large Language Models\n",
      "- Definition of LLMs and their capabilities in natural language processing\n",
      "- Examples of popular LLMs like GPT-3 and BERT\n",
      "- Potential applications of LLMs in chatbots, content generation, and more\n",
      "\n",
      "2. Latest Trends in Large Language Models\n",
      "- Discussion on the growing trend of using LLMs in various industries\n",
      "- Exploration of new research and developments in LLM technology\n",
      "- Impact of LLMs on the future of communication and information processing\n",
      "\n",
      "3. Key Players in the Industry\n",
      "- Overview of companies leading the development of LLMs\n",
      "- Comparison of different LLM models and their strengths\n",
      "- Collaboration between tech giants and research institutions in advancing LLM technology\n",
      "\n",
      "4. Target Audience Analysis\n",
      "- Identification of tech enthusiasts, data scientists, and AI researchers as primary audience\n",
      "- Understanding of audience interests in cutting-edge technology and AI applications\n",
      "- Addressing pain points related to understanding complex AI concepts and staying updated on industry trends\n",
      "\n",
      "Call to Action:\n",
      "- Encourage readers to explore the potential of LLMs in their respective fields\n",
      "- Provide resources for further reading on LLM technology and applications\n",
      "- Invite audience to share their thoughts and experiences with LLMs in the comments section\n",
      "\n",
      "SEO Keywords:\n",
      "- Large Language Models\n",
      "- GPT-3\n",
      "- BERT\n",
      "- Natural Language Processing\n",
      "- Artificial Intelligence\n",
      "- Tech Trends\n",
      "- AI Applications\n",
      "\n",
      "Resources:\n",
      "1. OpenAI's official website for updates on LLM research and projects\n",
      "2. Google AI Blog for insights on the latest advancements in AI technology\n",
      "3. Research papers on LLMs from academic institutions like Stanford and MIT\n",
      "\n",
      "Overall, this comprehensive content plan aims to educate and engage the audience on the topic of Large Language Models, providing valuable insights and resources for further exploration.\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Content Writer\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. Use the content plan to craft a compelling blog post on Large Language Models.\n",
      "2. Incorporate SEO keywords naturally.\n",
      "3. Sections/Subtitles are properly named in an engaging manner.\n",
      "4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
      "5. Proofread for grammatical errors and alignment with the brand's voice.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "# Unleashing the Power of Large Language Models: A Comprehensive Guide\n",
      "\n",
      "In the rapidly evolving field of artificial intelligence, Large Language Models (LLMs) have emerged as powerful tools with the potential to revolutionize how we interact with technology. Companies like OpenAI, Google, and Facebook are at the forefront of developing these advanced models, pushing the boundaries of what is possible in natural language processing. Recent advancements in LLM technology have sparked excitement across various sectors, from chatbots to content generation, showcasing the versatility and impact of these models.\n",
      "\n",
      "## Understanding Large Language Models\n",
      "\n",
      "Large Language Models, as the name suggests, are sophisticated AI systems capable of processing and generating human-like text. Popular examples include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers), which have garnered attention for their impressive language capabilities. These models have the potential to revolutionize how we communicate with machines, opening up new possibilities for personalized interactions and content creation. From improving chatbot responses to enhancing content generation algorithms, LLMs are driving innovation in the field of natural language processing.\n",
      "\n",
      "## Latest Trends in Large Language Models\n",
      "\n",
      "The use of Large Language Models is on the rise across various industries, as companies recognize the value of harnessing the power of AI-driven language processing. Researchers and developers are constantly exploring new ways to enhance LLM technology, pushing the boundaries of what is possible in communication and information processing. The impact of LLMs on the future of AI applications is undeniable, shaping the way we interact with technology and consume information in the digital age.\n",
      "\n",
      "## Key Players in the Industry\n",
      "\n",
      "Leading tech companies like OpenAI, Google, and Facebook are spearheading the development of Large Language Models, investing in research and collaboration to advance the capabilities of these models. Each company brings its unique strengths and expertise to the table, contributing to the evolution of LLM technology. The collaboration between tech giants and research institutions is crucial in driving innovation and pushing the boundaries of what is possible with LLMs.\n",
      "\n",
      "## Target Audience Analysis\n",
      "\n",
      "Tech enthusiasts, data scientists, and AI researchers form the primary audience for content on Large Language Models, as they seek to stay informed about the latest trends and developments in AI technology. Understanding the interests and pain points of this audience is essential in creating engaging and informative content that resonates with their needs. By addressing complex AI concepts and providing insights into industry trends, content creators can bridge the gap between cutting-edge technology and audience understanding.\n",
      "\n",
      "## Call to Action\n",
      "\n",
      "As we delve deeper into the world of Large Language Models, I encourage readers to explore the potential of these advanced AI systems in their respective fields. Resources from OpenAI, Google AI Blog, and academic institutions like Stanford and MIT offer valuable insights into the latest research and projects in the field of LLM technology. I invite readers to share their thoughts and experiences with LLMs in the comments section, fostering a community of learning and collaboration in the realm of artificial intelligence.\n",
      "\n",
      "In conclusion, Large Language Models have the power to transform how we interact with technology and process information, opening up new possibilities for innovation and creativity. By staying informed and engaged with the latest trends in LLM technology, we can harness the full potential of these advanced AI systems and shape the future of communication and information processing.\n",
      "\n",
      "---\n",
      "I have followed the content plan provided and incorporated the SEO keywords naturally throughout the blog post. Each section is structured with engaging subtitles and provides valuable insights into the topic of Large Language Models. I have proofread the content for grammatical errors and ensured alignment with the brand's voice.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [DEBUG]: == [Content Writer] Task output: # Unleashing the Power of Large Language Models: A Comprehensive Guide\n",
      "\n",
      "In the rapidly evolving field of artificial intelligence, Large Language Models (LLMs) have emerged as powerful tools with the potential to revolutionize how we interact with technology. Companies like OpenAI, Google, and Facebook are at the forefront of developing these advanced models, pushing the boundaries of what is possible in natural language processing. Recent advancements in LLM technology have sparked excitement across various sectors, from chatbots to content generation, showcasing the versatility and impact of these models.\n",
      "\n",
      "## Understanding Large Language Models\n",
      "\n",
      "Large Language Models, as the name suggests, are sophisticated AI systems capable of processing and generating human-like text. Popular examples include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers), which have garnered attention for their impressive language capabilities. These models have the potential to revolutionize how we communicate with machines, opening up new possibilities for personalized interactions and content creation. From improving chatbot responses to enhancing content generation algorithms, LLMs are driving innovation in the field of natural language processing.\n",
      "\n",
      "## Latest Trends in Large Language Models\n",
      "\n",
      "The use of Large Language Models is on the rise across various industries, as companies recognize the value of harnessing the power of AI-driven language processing. Researchers and developers are constantly exploring new ways to enhance LLM technology, pushing the boundaries of what is possible in communication and information processing. The impact of LLMs on the future of AI applications is undeniable, shaping the way we interact with technology and consume information in the digital age.\n",
      "\n",
      "## Key Players in the Industry\n",
      "\n",
      "Leading tech companies like OpenAI, Google, and Facebook are spearheading the development of Large Language Models, investing in research and collaboration to advance the capabilities of these models. Each company brings its unique strengths and expertise to the table, contributing to the evolution of LLM technology. The collaboration between tech giants and research institutions is crucial in driving innovation and pushing the boundaries of what is possible with LLMs.\n",
      "\n",
      "## Target Audience Analysis\n",
      "\n",
      "Tech enthusiasts, data scientists, and AI researchers form the primary audience for content on Large Language Models, as they seek to stay informed about the latest trends and developments in AI technology. Understanding the interests and pain points of this audience is essential in creating engaging and informative content that resonates with their needs. By addressing complex AI concepts and providing insights into industry trends, content creators can bridge the gap between cutting-edge technology and audience understanding.\n",
      "\n",
      "## Call to Action\n",
      "\n",
      "As we delve deeper into the world of Large Language Models, I encourage readers to explore the potential of these advanced AI systems in their respective fields. Resources from OpenAI, Google AI Blog, and academic institutions like Stanford and MIT offer valuable insights into the latest research and projects in the field of LLM technology. I invite readers to share their thoughts and experiences with LLMs in the comments section, fostering a community of learning and collaboration in the realm of artificial intelligence.\n",
      "\n",
      "In conclusion, Large Language Models have the power to transform how we interact with technology and process information, opening up new possibilities for innovation and creativity. By staying informed and engaged with the latest trends in LLM technology, we can harness the full potential of these advanced AI systems and shape the future of communication and information processing.\n",
      "\n",
      "---\n",
      "I have followed the content plan provided and incorporated the SEO keywords naturally throughout the blog post. Each section is structured with engaging subtitles and provides valuable insights into the topic of Large Language Models. I have proofread the content for grammatical errors and ensured alignment with the brand's voice.\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Editor\u001b[00m\n",
      "\u001b[1m\u001b[95m [INFO]: == Starting Task: Proofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "# Unleashing the Power of Large Language Models: A Comprehensive Guide\n",
      "\n",
      "In the rapidly evolving field of artificial intelligence, Large Language Models (LLMs) have emerged as powerful tools with the potential to revolutionize how we interact with technology. Companies like OpenAI, Google, and Facebook are at the forefront of developing these advanced models, pushing the boundaries of what is possible in natural language processing. Recent advancements in LLM technology have sparked excitement across various sectors, from chatbots to content generation, showcasing the versatility and impact of these models.\n",
      "\n",
      "## Understanding Large Language Models\n",
      "\n",
      "Large Language Models, as the name suggests, are sophisticated AI systems capable of processing and generating human-like text. Popular examples include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers), which have garnered attention for their impressive language capabilities. These models have the potential to revolutionize how we communicate with machines, opening up new possibilities for personalized interactions and content creation. From improving chatbot responses to enhancing content generation algorithms, LLMs are driving innovation in the field of natural language processing.\n",
      "\n",
      "## Latest Trends in Large Language Models\n",
      "\n",
      "The use of Large Language Models is on the rise across various industries, as companies recognize the value of harnessing the power of AI-driven language processing. Researchers and developers are constantly exploring new ways to enhance LLM technology, pushing the boundaries of what is possible in communication and information processing. The impact of LLMs on the future of AI applications is undeniable, shaping the way we interact with technology and consume information in the digital age.\n",
      "\n",
      "## Key Players in the Industry\n",
      "\n",
      "Leading tech companies like OpenAI, Google, and Facebook are spearheading the development of Large Language Models, investing in research and collaboration to advance the capabilities of these models. Each company brings its unique strengths and expertise to the table, contributing to the evolution of LLM technology. The collaboration between tech giants and research institutions is crucial in driving innovation and pushing the boundaries of what is possible with LLMs.\n",
      "\n",
      "## Target Audience Analysis\n",
      "\n",
      "Tech enthusiasts, data scientists, and AI researchers form the primary audience for content on Large Language Models, as they seek to stay informed about the latest trends and developments in AI technology. Understanding the interests and pain points of this audience is essential in creating engaging and informative content that resonates with their needs. By addressing complex AI concepts and providing insights into industry trends, content creators can bridge the gap between cutting-edge technology and audience understanding.\n",
      "\n",
      "## Call to Action\n",
      "\n",
      "As we delve deeper into the world of Large Language Models, I encourage readers to explore the potential of these advanced AI systems in their respective fields. Resources from OpenAI, Google AI Blog, and academic institutions like Stanford and MIT offer valuable insights into the latest research and projects in the field of LLM technology. I invite readers to share their thoughts and experiences with LLMs in the comments section, fostering a community of learning and collaboration in the realm of artificial intelligence.\n",
      "\n",
      "In conclusion, Large Language Models have the power to transform how we interact with technology and process information, opening up new possibilities for innovation and creativity. By staying informed and engaged with the latest trends in LLM technology, we can harness the full potential of these advanced AI systems and shape the future of communication and information processing.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [DEBUG]: == [Editor] Task output: # Unleashing the Power of Large Language Models: A Comprehensive Guide\n",
      "\n",
      "In the rapidly evolving field of artificial intelligence, Large Language Models (LLMs) have emerged as powerful tools with the potential to revolutionize how we interact with technology. Companies like OpenAI, Google, and Facebook are at the forefront of developing these advanced models, pushing the boundaries of what is possible in natural language processing. Recent advancements in LLM technology have sparked excitement across various sectors, from chatbots to content generation, showcasing the versatility and impact of these models.\n",
      "\n",
      "## Understanding Large Language Models\n",
      "\n",
      "Large Language Models, as the name suggests, are sophisticated AI systems capable of processing and generating human-like text. Popular examples include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers), which have garnered attention for their impressive language capabilities. These models have the potential to revolutionize how we communicate with machines, opening up new possibilities for personalized interactions and content creation. From improving chatbot responses to enhancing content generation algorithms, LLMs are driving innovation in the field of natural language processing.\n",
      "\n",
      "## Latest Trends in Large Language Models\n",
      "\n",
      "The use of Large Language Models is on the rise across various industries, as companies recognize the value of harnessing the power of AI-driven language processing. Researchers and developers are constantly exploring new ways to enhance LLM technology, pushing the boundaries of what is possible in communication and information processing. The impact of LLMs on the future of AI applications is undeniable, shaping the way we interact with technology and consume information in the digital age.\n",
      "\n",
      "## Key Players in the Industry\n",
      "\n",
      "Leading tech companies like OpenAI, Google, and Facebook are spearheading the development of Large Language Models, investing in research and collaboration to advance the capabilities of these models. Each company brings its unique strengths and expertise to the table, contributing to the evolution of LLM technology. The collaboration between tech giants and research institutions is crucial in driving innovation and pushing the boundaries of what is possible with LLMs.\n",
      "\n",
      "## Target Audience Analysis\n",
      "\n",
      "Tech enthusiasts, data scientists, and AI researchers form the primary audience for content on Large Language Models, as they seek to stay informed about the latest trends and developments in AI technology. Understanding the interests and pain points of this audience is essential in creating engaging and informative content that resonates with their needs. By addressing complex AI concepts and providing insights into industry trends, content creators can bridge the gap between cutting-edge technology and audience understanding.\n",
      "\n",
      "## Call to Action\n",
      "\n",
      "As we delve deeper into the world of Large Language Models, I encourage readers to explore the potential of these advanced AI systems in their respective fields. Resources from OpenAI, Google AI Blog, and academic institutions like Stanford and MIT offer valuable insights into the latest research and projects in the field of LLM technology. I invite readers to share their thoughts and experiences with LLMs in the comments section, fostering a community of learning and collaboration in the realm of artificial intelligence.\n",
      "\n",
      "In conclusion, Large Language Models have the power to transform how we interact with technology and process information, opening up new possibilities for innovation and creativity. By staying informed and engaged with the latest trends in LLM technology, we can harness the full potential of these advanced AI systems and shape the future of communication and information processing.\n",
      "\n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={\"topic\": \"Large Language Models\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16504b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Unleashing the Power of Large Language Models: A Comprehensive Guide\n",
       "\n",
       "In the rapidly evolving field of artificial intelligence, Large Language Models (LLMs) have emerged as powerful tools with the potential to revolutionize how we interact with technology. Companies like OpenAI, Google, and Facebook are at the forefront of developing these advanced models, pushing the boundaries of what is possible in natural language processing. Recent advancements in LLM technology have sparked excitement across various sectors, from chatbots to content generation, showcasing the versatility and impact of these models.\n",
       "\n",
       "## Understanding Large Language Models\n",
       "\n",
       "Large Language Models, as the name suggests, are sophisticated AI systems capable of processing and generating human-like text. Popular examples include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers), which have garnered attention for their impressive language capabilities. These models have the potential to revolutionize how we communicate with machines, opening up new possibilities for personalized interactions and content creation. From improving chatbot responses to enhancing content generation algorithms, LLMs are driving innovation in the field of natural language processing.\n",
       "\n",
       "## Latest Trends in Large Language Models\n",
       "\n",
       "The use of Large Language Models is on the rise across various industries, as companies recognize the value of harnessing the power of AI-driven language processing. Researchers and developers are constantly exploring new ways to enhance LLM technology, pushing the boundaries of what is possible in communication and information processing. The impact of LLMs on the future of AI applications is undeniable, shaping the way we interact with technology and consume information in the digital age.\n",
       "\n",
       "## Key Players in the Industry\n",
       "\n",
       "Leading tech companies like OpenAI, Google, and Facebook are spearheading the development of Large Language Models, investing in research and collaboration to advance the capabilities of these models. Each company brings its unique strengths and expertise to the table, contributing to the evolution of LLM technology. The collaboration between tech giants and research institutions is crucial in driving innovation and pushing the boundaries of what is possible with LLMs.\n",
       "\n",
       "## Target Audience Analysis\n",
       "\n",
       "Tech enthusiasts, data scientists, and AI researchers form the primary audience for content on Large Language Models, as they seek to stay informed about the latest trends and developments in AI technology. Understanding the interests and pain points of this audience is essential in creating engaging and informative content that resonates with their needs. By addressing complex AI concepts and providing insights into industry trends, content creators can bridge the gap between cutting-edge technology and audience understanding.\n",
       "\n",
       "## Call to Action\n",
       "\n",
       "As we delve deeper into the world of Large Language Models, I encourage readers to explore the potential of these advanced AI systems in their respective fields. Resources from OpenAI, Google AI Blog, and academic institutions like Stanford and MIT offer valuable insights into the latest research and projects in the field of LLM technology. I invite readers to share their thoughts and experiences with LLMs in the comments section, fostering a community of learning and collaboration in the realm of artificial intelligence.\n",
       "\n",
       "In conclusion, Large Language Models have the power to transform how we interact with technology and process information, opening up new possibilities for innovation and creativity. By staying informed and engaged with the latest trends in LLM technology, we can harness the full potential of these advanced AI systems and shape the future of communication and information processing."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2409740b",
   "metadata": {},
   "source": [
    "##We can use other models:\n",
    "\n",
    "Hugging Face (HuggingFaceHub endpoint)\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    huggingfacehub_api_token=\"<HF_TOKEN_HERE>\",\n",
    "    task=\"text-generation\",\n",
    ")\n",
    "\n",
    "#######  you will pass \"llm\" to your agent function\n",
    "\n",
    "for Mistral API\n",
    "OPENAI_API_KEY=your-mistral-api-key\n",
    "OPENAI_API_BASE=https://api.mistral.ai/v1\n",
    "OPENAI_MODEL_NAME=\"mistral-small\"\n",
    "\n",
    "\n",
    "for Cohere\n",
    "from langchain_community.chat_models import ChatCohere\n",
    "####### Initialize language model\n",
    "os.environ[\"COHERE_API_KEY\"] = \"your-cohere-api-key\"\n",
    "llm = ChatCohere()\n",
    "\n",
    "####### just pass \"llm\" to your agent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd158b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec41a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
